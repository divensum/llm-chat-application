langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=phi3
langchain4j.ollama.chat-model.temperature=0.8
langchain4j.ollama.chat-model.timeout=PT60S
langchain4j.ollama.chat-model.log-requests=true
angchain4j.ollama.chat-model.log-responses=true

langchain4j.ollama.streaming-chat-model.base-url=http://localhost:11434
langchain4j.ollama.streaming-chat-model.model-name=phi3
langchain4j.ollama.streaming-chat-model.temperature=0.8
langchain4j.ollama.streaming-chat-model.timeout=PT60S
langchain4j.ollama.streaming-chat-model.log-requests=true
langchain4j.ollama.streaming-chat-model.log-responses=true